params.executor = "slurm"

// define your preferred queues here
params.default_queue = 'my-queue-name'  // Default queue
params.gpu_queue = null  // Optional: Only set if GPU queue is needed and different from default queue

// Detect engine: prefer apptainer if available, else singularity
def hasApptainer = ['bash','-c','command -v apptainer'].execute().waitFor() == 0
def hasSingularity = ['bash','-c','command -v singularity'].execute().waitFor() == 0

if( hasApptainer ) {
    apptainer {
        enabled = true
        autoMounts = true
        apptainer.enabled = true
        apptainer.autoMounts = true
        platform = 'linux/amd64'
        envWhitelist = ['KACHERY_ZONE', 'KACHERY_API_KEY', 'NUMBA_CACHE_DIR', 'HDF5_USE_FILE_LOCKING']
    }
}
else if( hasSingularity ) {
    singularity {
        enabled = true
        autoMounts = true
        singularity.enabled = true
        singularity.autoMounts = true
        platform = 'linux/amd64'
        envWhitelist = ['KACHERY_ZONE', 'KACHERY_API_KEY', 'NUMBA_CACHE_DIR', 'HDF5_USE_FILE_LOCKING']
    }
}
else {
    throw new RuntimeException("Neither apptainer nor singularity found in PATH")
}

process {
    executor = 'slurm'
    queue = params.default_queue  // Default queue assignment
    debug = true

    // change max forks for specific processes to allow multiple forks
    withName: job_dispatch {
        cpus=4
        memory='32 GB'
        time='1h'
    }
    // time can be specified as absolute time (e.g. '1h') or as relative to the recording duration
    // e.g. time={ max_duration_minutes.toFloat()*4 + 'm' } means 4x recording duration
    withName: hybrid_generation {
        cpus=16
        memory='64 GB'
        // Allocate 4x recording duration
        time={ max_duration_minutes.toFloat()*4 + 'm' }
    }
    withName: preprocessing {
        cpus=16
        memory='64 GB'
        // Allocate 4x recording duration
        time={ max_duration_minutes.toFloat()*4 + 'm' }
    }
    withName: compress_wavpack {
        cpus=16
        memory='64 GB'
        // Allocate 4x recording duration
        time={ max_duration_minutes.toFloat()*4 + 'm' }
    }
    withName: spikesort_kilosort4 {
        cpus=16
        memory='64 GB'
        containerOptions='--nv'
        clusterOptions='--gres=gpu:1'
        queue=params.gpu_queue ?: params.default_queue
        // Some systems may require 'module cuda' directive
        // module cuda
        // Allocate 4x recording duration
        time={ max_duration_minutes.toFloat()*4 + 'm' }
    }
    withName: spikesort_kilosort25 {
        cpus=16
        memory='64 GB'
        containerOptions='--nv'
        clusterOptions='--gres=gpu:1'
        queue=params.gpu_queue ?: params.default_queue
        // Some systems may require 'module cuda' directive
        // module cuda
        // Allocate 4x recording duration
        time={ max_duration_minutes.toFloat()*4 + 'm' }
    }
    withName: spikesort_spykingcircus2 {
        cpus=16
        memory='64 GB'
        // Allocate 4x recording duration
        time={ max_duration_minutes.toFloat()*4 + 'm' }
    }
    withName: hybrid_evaluation {
        cpus=16
        memory='64 GB'
        // Allocate 4x recording duration
        time={ max_duration_minutes.toFloat()*4 + 'm' }
    }
}


dag {
    enabled = true
    file = RESULTS_PATH + '/nextflow/dag.html'
    overwrite = true
}

report {
    enabled = true
    file = RESULTS_PATH + '/nextflow/report.html'
    overwrite = true
}

timeline {
    enabled = true
    file = RESULTS_PATH + '/nextflow/timeline.html'
    overwrite = true
}

trace {
    enabled = true
    file = RESULTS_PATH + '/nextflow/trace.txt'
    overwrite = true
}
